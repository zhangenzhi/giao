{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "# modules\n",
    "from dataloader import Cifar10DataLoader\n",
    "from dnn import DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_args = edict({\"batch_size\": 128, \"epochs\": 100, \"da\": False})\n",
    "dataloader = Cifar10DataLoader(dataloader_args=dataloader_args)\n",
    "source_train_ds,source_test_ds,target_train_ds,target_test_ds = dataloader.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = edict({\"units\":[128,64,32,10], \"activations\":[\"relu\",\"relu\",\"relu\",\"softmax\"]})\n",
    "model = DNN(units=model_args.units, activations=model_args.activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "mt_loss_fn = tf.keras.metrics.Mean()\n",
    "test_loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "mte_loss_fn = tf.keras.metrics.Mean()\n",
    "\n",
    "train_metrics = tf.keras.metrics.CategoricalAccuracy()\n",
    "test_metrics = tf.keras.metrics.CategoricalAccuracy()\n",
    "optimizer = tf.keras.optimizers.SGD(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function(experimental_relax_shapes=True, experimental_compile=None)\n",
    "def _train_step(inputs, labels, first_batch=False):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs)\n",
    "        loss = train_loss_fn(labels, predictions)\n",
    "        metrics = tf.reduce_mean(train_metrics(labels, predictions))\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    mt_loss_fn.update_state(loss)\n",
    "    \n",
    "    return loss, metrics\n",
    "\n",
    "def _test_step(inputs, labels):\n",
    "    predictions = model(inputs)\n",
    "    loss = test_loss_fn(labels, predictions)\n",
    "    metrics = tf.reduce_mean(test_metrics(labels, predictions))\n",
    "    mte_loss_fn.update_state(loss)\n",
    "    \n",
    "    return loss, metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12 (main, Jun  1 2022, 06:34:44) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14ddbbabdf1cc89aed24e001be3922f4034073f682acd1338a644a14376bd924"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
